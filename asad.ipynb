{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "QUyh8COdopYj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEPENDENCIES"
      ],
      "metadata": {
        "id": "DHIXrYBhp4Bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q together openai groq regex"
      ],
      "metadata": {
        "id": "BiF5eWNDtB-V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be57d29b-3bc5-4527-cdea-2c75dc2f3b09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/318.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m317.4/318.3 kB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m318.3/318.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/138.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "import regex\n",
        "from together import Together\n",
        "from openai import OpenAI\n",
        "from groq import Groq\n",
        "from typing import List, Dict, Any"
      ],
      "metadata": {
        "id": "1Dhw3f3C88s8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "API KEYs & CLIENTS"
      ],
      "metadata": {
        "id": "RWcfo9cFqBsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"TOGETHER_API_KEY\"] = \"PUT YOUR API KEY HERE\"\n",
        "os.environ[\"GROQ_API_KEY\"] = \"PUT YOUR API KEY HERE\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"PUT YOUR API KEY HERE\""
      ],
      "metadata": {
        "id": "ewjmsuPQ9HrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tg_client = Together(api_key=os.environ.get(\"TOGETHER_API_KEY\"))\n",
        "gq_client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
        "op_client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))"
      ],
      "metadata": {
        "id": "hICjbFM5c5ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CALL LLM"
      ],
      "metadata": {
        "id": "qkS-2oGi9upu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "provider=\"together\"\n",
        "\n",
        "def call_llm (question : str):\n",
        "  if provider == \"together\":\n",
        "    response = tg_client.chat.completions.create(\n",
        "      model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": question\n",
        "          }\n",
        "      ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "  elif provider == \"groq\":\n",
        "    response = gq_client.chat.completions.create(\n",
        "        model=\"groq/compound-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "              \"role\": \"user\",\n",
        "              \"content\":question\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    return(response.choices[0].message.content)\n",
        "  else:\n",
        "    response = op_client.responses.create(\n",
        "        model=\"gpt-5\",\n",
        "        input=question,\n",
        "        reasoning={ \"effort\": \"low\" },\n",
        "        text={ \"verbosity\": \"low\" },\n",
        "    )\n",
        "\n",
        "    return(response.output_text)"
      ],
      "metadata": {
        "id": "2Y_YaGfbtFC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OUTPUT FORMATTING HELPERS"
      ],
      "metadata": {
        "id": "kwykesd79l56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cleanCODE(text):\n",
        "    # Split the text into lines\n",
        "    lines = text.strip().split('\\n')\n",
        "\n",
        "    if lines and lines[0].startswith('```'):\n",
        "        lines = lines[1:]\n",
        "\n",
        "    closing_index = None\n",
        "    for i, line in enumerate(lines):\n",
        "        if '```' in line:\n",
        "            closing_index = i\n",
        "            break\n",
        "\n",
        "    if closing_index is not None:\n",
        "        lines = lines[:closing_index]\n",
        "    clean_text = '\\n'.join(lines)\n",
        "\n",
        "    return clean_text\n",
        "\n",
        "def cleanJSON(text):\n",
        "    matchy = regex.search(r'\\{(?:[^{}]|(?R))*\\}', text)\n",
        "    return(matchy.group())\n",
        "\n",
        "\n",
        "def safe_json_parse(response: str, fallback: Any = None) -> Any:\n",
        "    try:\n",
        "        clean_response = cleanJSON(response)\n",
        "        return json.loads(clean_response)\n",
        "    except json.JSONDecodeError:\n",
        "        # Fix invalid escape sequences by double-escaping\n",
        "        clean_response = re.sub(r'\\\\(?![\"\\\\/bfnrtu])', r'\\\\\\\\', clean_response)\n",
        "        try:\n",
        "            return json.loads(clean_response)\n",
        "        except json.JSONDecodeError:\n",
        "            return fallback"
      ],
      "metadata": {
        "id": "0tmmpE990i_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MAIN AGENT FUNCTIONS"
      ],
      "metadata": {
        "id": "qze0b-ZJ9iXS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK ANALYSIS"
      ],
      "metadata": {
        "id": "FBiQb2_8poNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_problem(code: str) -> Dict[str, Any]:\n",
        "    prompt =f\"\"\"\n",
        "    Role: You are the Main Analysis Agent. Your responsibility\n",
        "    is to perform a systematic static analysis of the given\n",
        "    code and identify defects that prevent correct execution.\n",
        "\n",
        "    Input: Buggy code: {code}\n",
        "\n",
        "    Instructions:\n",
        "    1. Assess the complexity of the debugging task and classify\n",
        "    it as SIMPLE or COMPLEX based on the following criterias:\n",
        "      - Number of critical bugs\n",
        "      - Degree of bug isolation\n",
        "      - Clarity of control flow\n",
        "      - Concurrency or resource management issues\n",
        "      - Inter-function or module coupling\n",
        "    2. Identify and precisely locate all bugs that may prevent\n",
        "    the code from executing correctly. For each bug, specify:\n",
        "      - Bug type (e.g., syntax error, API misuse, ...)\n",
        "      - Location (function name, line number range)\n",
        "      - Brief explanation of why it causes failure\n",
        "    3. Produce a structured, step-by-step repair plan\n",
        "    describing how the identified bugs should be fixed.\n",
        "\n",
        "    Output:Return a JSON object with the following schema:\n",
        "    {{\n",
        "      complexity\": \"SIMPLE\" or \"COMPLEX\",\n",
        "      \"bugs\": [\n",
        "        {{\n",
        "          \"type\": \"...\",\n",
        "          \"location\": \"...\",\n",
        "          \"explanation\": \"...\"\n",
        "        }}\n",
        "      ],\n",
        "      \"plan\": \"...\"\n",
        "    }}\n",
        "    Do not write any text besides the JSON.\n",
        "    \"\"\"\n",
        "    result = call_llm(prompt)\n",
        "    parsed = safe_json_parse(result, fallback={\"complexity\": \"SIMPLE\", \"bugs\":\"...\", \"plan\": \"...\"})\n",
        "    return parsed"
      ],
      "metadata": {
        "id": "O1h7n9lEPxT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NEW ITERATION ANALYSIS"
      ],
      "metadata": {
        "id": "7aVqYnAKqLaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def new_iteration_analyze_problem(code: str, failure_log: Dict[str, Any], previous_plan: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    prompt =f\"\"\"\n",
        "    Role:\n",
        "        You are the Main Analysis Agent. Your responsibility is to perform a systematic review\n",
        "        of the given code after a previous fix attempt has failed. Identify all remaining defects\n",
        "        that prevent execution and generate a precise new repair plan. Do not provide suggestions\n",
        "        or potential improvements.\n",
        "\n",
        "    Input:\n",
        "        Previous repair plan: {previous_plan}\n",
        "        Failure summary: {failure_log[\"summary\"]}\n",
        "        Buggy code: {code}\n",
        "\n",
        "    Instructions:\n",
        "    1. Assess the complexity of the remaining debugging task and classify it as SIMPLE or COMPLEX\n",
        "      using the following criteria:\n",
        "          - Number of critical bugs remaining\n",
        "          - Degree of bug isolation\n",
        "          - Clarity of control flow\n",
        "          - Presence of concurrency or resource management issues\n",
        "          - Dependencies between functions or modules\n",
        "    2. Identify all remaining bugs, specifying for each:\n",
        "          - Bug type (e.g., syntax error, API misuse, logic error)\n",
        "          - Location (function name, line number range)\n",
        "          - Explanation of why it prevents correct execution\n",
        "    3. Produce a step-by-step new repair plan detailing how to fix the remaining bugs.\n",
        "\n",
        "    Output:\n",
        "    Return a JSON object with this schema:\n",
        "    {{\n",
        "      \"complexity\": \"SIMPLE\" or \"COMPLEX\",\n",
        "      \"bugs\": [\n",
        "        {{\n",
        "          \"type\": \"...\",\n",
        "          \"location\": \"...\",\n",
        "          \"explanation\": \"...\"\n",
        "        }}\n",
        "      ],\n",
        "      \"plan\":\"...\"\n",
        "    }}\n",
        "    Do not write any text besides the JSON.\n",
        "    \"\"\"\n",
        "    result = call_llm(prompt)\n",
        "    parsed = safe_json_parse(result, fallback={\"complexity\": \"SIMPLE\", \"bugs\":\"...\", \"plan\": \"...\"})\n",
        "    return parsed"
      ],
      "metadata": {
        "id": "PtBY2gNf-CX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AGENTS CREATION AND PRIORITIZATION"
      ],
      "metadata": {
        "id": "2XkIGUITqSMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_agents(bugs: List[Any], plan: str) -> List[Dict[str, Any]]:\n",
        "    prompt = f\"\"\"\n",
        "    Role:\n",
        "        You are the Main Agent responsible for creating and organizing specialized agent profiles.\n",
        "        Your task is twofold:\n",
        "        1. Generate the minimum set of agents required to fix the located bugs.\n",
        "        2. Prioritize these agents based on their dependencies to ensure correct execution order.\n",
        "\n",
        "    Input:\n",
        "        Located bugs: {bugs}\n",
        "        Repair instructions: {plan}\n",
        "\n",
        "    Instructions:\n",
        "\n",
        "    Step 1 - Agent Generation:\n",
        "        1. Generate the minimum set of agents required to fix the bugs.\n",
        "        2. For each agent, provide:\n",
        "            - name\n",
        "            - role\n",
        "            - task_description (phrased as \"Your task is to...\" and explicitly referencing the located errors)\n",
        "\n",
        "    Step 2 - Agent Prioritization:\n",
        "        1. Determine dependencies between agents (e.g., syntax must be fixed before logic errors).\n",
        "        2. Order the agents based on these dependencies.\n",
        "\n",
        "    Output:\n",
        "    Return a JSON object with the following schema:\n",
        "\n",
        "    {{\n",
        "      \"agents\": [\n",
        "        {{\n",
        "          \"name\": \"...\",\n",
        "          \"role\": \"...\",\n",
        "          \"task_description\": \"...\"\n",
        "        }}\n",
        "      ],\n",
        "      \"execution_order\": [\"Agent_1_name\", \"Agent_2_name\", \"...\"]\n",
        "    }}\n",
        "\n",
        "    Do not write any text besides the JSON.\n",
        "    \"\"\"\n",
        "\n",
        "    result = call_llm(prompt)\n",
        "    parsed = safe_json_parse(result, fallback={\"agents\": [], \"execution_order\": []})\n",
        "    return parsed\n"
      ],
      "metadata": {
        "id": "zcluLVY1TCfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ITERATIVE TASK REVIEW"
      ],
      "metadata": {
        "id": "NN3-bYmPqXbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def task_review(agent: Dict[str, Any], agent_report: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    prompt = f\"\"\"\n",
        "    Role:\n",
        "    You are the Main Agent responsible of reviewing the output of a specialized debugging agent.\n",
        "    Your task is to make the decision whether to approve or refine the agent fixes.\n",
        "\n",
        "    Input:\n",
        "    The agent task description,\n",
        "    {agent[\"task_description\"]}\n",
        "    The proposed fixed code\n",
        "    {agent_report[\"fixed_code\"]}\n",
        "    The fix explanation:\n",
        "    {agent_report[\"fix_explanation\"]}\n",
        "\n",
        "    Instructions:\n",
        "    1. Check whether the agent\\'s changes are correct and complete.\n",
        "    2. If yes, approve and move to the next agent.\n",
        "    3. If no, instruct the same agent to refine its work.\n",
        "\n",
        "    Your output in JSON format in the following fromat:\n",
        "    {{\n",
        "      \"decision\": \"APPROVE\" or \"REFINE\",\n",
        "      \"feedback\": \"...\" // if refinement is needed\n",
        "    }}\n",
        "\n",
        "    Do not write any text besides the JSON.\n",
        "    \"\"\"\n",
        "    result = call_llm(prompt)\n",
        "    parsed = safe_json_parse(result, fallback={\"decision\": \"\", \"feedback\":\"\"})\n",
        "    return parsed"
      ],
      "metadata": {
        "id": "0v3KeoHJyboO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINAL VALIDATION"
      ],
      "metadata": {
        "id": "seTJcsB7qbCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_solution(code: str) -> Dict[str, Any]:\n",
        "    prompt = f\"\"\"\n",
        "    Role:\n",
        "        You are the Master Agent responsible for final validation and closure.\n",
        "        Your task is to verify whether the given code is fully fixed and executable.\n",
        "        Focus only on bugs that prevent correct execution.\n",
        "\n",
        "    Input:\n",
        "        Buggy code: {code}\n",
        "\n",
        "    Instructions:\n",
        "    1. Check whether the code is free of execution-blocking bugs.\n",
        "    2. If the code is fully fixed, confirm completion.\n",
        "    3. If not, summarize and explain all remaining bugs.\n",
        "\n",
        "    Output:\n",
        "    Return a JSON object with this schema:\n",
        "\n",
        "    {{\n",
        "      \"status\": \"FIXED\" or \"NOT FIXED\",\n",
        "      \"summary\": \"...\",\n",
        "      \"remaining_bugs\": [\n",
        "        {{\n",
        "          \"type\": \"...\",\n",
        "          \"location\": \"...\",\n",
        "          \"explanation\": \"...\"\n",
        "        }}\n",
        "      ],\n",
        "      \"explanation\": \"...\"\n",
        "    }}\n",
        "\n",
        "    Do not write any text besides the JSON.\n",
        "    \"\"\"\n",
        "\n",
        "    result = call_llm(prompt)\n",
        "    parsed = safe_json_parse(result, fallback={\"status\": \"NOT FIXED\", \"summary\": \"Parsing failed.\", \"remaining_bugs\": [], \"explanation\":\"\"})\n",
        "    return parsed"
      ],
      "metadata": {
        "id": "D2w9FYJjxcts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SIMPLE BUGS FAST FIX"
      ],
      "metadata": {
        "id": "fkqTA6AZqeED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_fix(bugs: List[Any], code: str) -> Dict[str, Any]:\n",
        "    prompt = f\"\"\"\n",
        "    Role:\n",
        "        You are a Code Repair Expert. Your task is to fix all identified bugs in the given code\n",
        "        and produce a fully corrected version.\n",
        "\n",
        "    Input:\n",
        "        Buggy code: {code}\n",
        "        Summary of issues: {bugs}\n",
        "\n",
        "    Instructions:\n",
        "    1. Fix the code to eliminate all execution-blocking bugs.\n",
        "    2. Provide a clear explanation of each fix applied.\n",
        "\n",
        "    Output:\n",
        "    Return a JSON object with all newlines and quotes escaped (e.g., \\\\n, \\\\\"):\n",
        "\n",
        "    {{\n",
        "      \"fixed_code\": \"...\",\n",
        "      \"fix_explanation\": \"...\"\n",
        "    }}\n",
        "\n",
        "    Do not write any text besides the JSON.\n",
        "    \"\"\"\n",
        "\n",
        "    result = call_llm(prompt)\n",
        "    parsed = safe_json_parse(result, fallback={\"fixed_code\": \"\", \"fix_explanation\":\"\"})\n",
        "    return parsed"
      ],
      "metadata": {
        "id": "0vRD8h3yw3mU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SPECIALIZED AGENT TASK EXECUTION\n",
        "\n"
      ],
      "metadata": {
        "id": "mcxB7urV9ax-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXECUTE TASK"
      ],
      "metadata": {
        "id": "AOrJBQyWqoTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def execute_agent(agent: Dict[str, Any], code: str) -> Dict[str, Any]:\n",
        "    prompt = f\"\"\"\n",
        "    Role:\n",
        "        You are a {agent[\"role\"]}.\n",
        "        Your task is to {agent[\"task_description\"]}.\n",
        "\n",
        "    Input:\n",
        "        Buggy code: {code}\n",
        "\n",
        "    Instructions:\n",
        "    1. Fix the code to address the issues within your responsibility.\n",
        "    2. Provide a clear explanation of the fix applied.\n",
        "\n",
        "    Output:\n",
        "    Return a JSON object with all newlines and quotes escaped (e.g., \\\\n, \\\\\"):\n",
        "\n",
        "    {{\n",
        "      \"fixed_code\": \"...\",\n",
        "      \"fix_explanation\": \"...\"\n",
        "    }}\n",
        "\n",
        "    Do not write any text besides the JSON.\n",
        "    \"\"\"\n",
        "\n",
        "    result = call_llm(prompt)\n",
        "    parsed = safe_json_parse(result, fallback={\"fixed_code\": \"\", \"fix_explanation\":\"\"})\n",
        "    return parsed"
      ],
      "metadata": {
        "id": "TjG-qaU4sbLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "REPEAT TASK"
      ],
      "metadata": {
        "id": "Iyw-RQ7DqrBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def retry_execute_agent(agent: Dict[str, Any], code: str, feedback: str) -> Dict[str, Any]:\n",
        "    prompt = f\"\"\"\n",
        "    Role:\n",
        "        You are a {agent[\"role\"]}.\n",
        "        Your task is to {agent[\"task_description\"]}.\n",
        "        You previously attempted a fix that failed. Now, fix the code again using the provided feedback.\n",
        "\n",
        "    Input:\n",
        "        Buggy code: {code}\n",
        "        Feedback: {feedback}\n",
        "\n",
        "    Instructions:\n",
        "    1. Fix the code, taking the feedback into account.\n",
        "    2. Provide a clear explanation of the fix applied.\n",
        "\n",
        "    Output:\n",
        "    Return a JSON object with all newlines and quotes escaped (e.g., \\\\n, \\\\\"):\n",
        "\n",
        "    {{\n",
        "      \"fixed_code\": \"...\",\n",
        "      \"fix_explanation\": \"...\"\n",
        "    }}\n",
        "\n",
        "    Do not write any text besides the JSON.\n",
        "    \"\"\"\n",
        "\n",
        "    result = call_llm(prompt)\n",
        "    parsed = safe_json_parse(result, fallback={\"fixed_code\": \"\", \"fix_explanation\":\"\"})\n",
        "    return parsed"
      ],
      "metadata": {
        "id": "hoHWyHTq1ZOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MAIN EXECUTION PIPELINE"
      ],
      "metadata": {
        "id": "aThXGg9_-DLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adaptive_debugger(buggy_code: str, max_iterations: int = 5):\n",
        "    analysis_report = analyze_problem(buggy_code)\n",
        "    print(analysis_report)\n",
        "    if not analysis_report[\"bugs\"]:\n",
        "        print(\"\\nðŸŸ¢ No errors found. Code is already fixed\")\n",
        "        return buggy_code\n",
        "\n",
        "    for iteration in range(max_iterations):\n",
        "\n",
        "        print(f\"\\n--------------ITERATION {iteration + 1}\")\n",
        "\n",
        "        if analysis_report[\"complexity\"] == \"SIMPLE\":\n",
        "            print(\"\\n--------------USING SIMPLE FIX\")\n",
        "            code_to_debug=simple_fix(analysis_report[\"bugs\"], buggy_code)\n",
        "\n",
        "        else:\n",
        "            print(\"\\n--------------USING MULTI AGENTS\")\n",
        "\n",
        "            created_agents= generate_agents(analysis_report['bugs'], analysis_report['plan'])\n",
        "            agent_profiles= created_agents[\"agents\"]\n",
        "            execution_order = created_agents[\"execution_order\"]\n",
        "\n",
        "\n",
        "            print(\"\\nNumber of Created Agents:\", len(agent_profiles))\n",
        "            print(\"\\nExecution Order: \" +\" -> \".join(execution_order))\n",
        "            reports = []\n",
        "            code_to_debug = buggy_code\n",
        "            for agent_name in execution_order:\n",
        "                print(f\"\\nExecuting Agent: {agent_name}\")\n",
        "                agent = next((a for a in agent_profiles if a[\"name\"] == agent_name), None)\n",
        "                if not agent:\n",
        "                    continue\n",
        "                decision=\"\"\n",
        "                feedback=\"\"\n",
        "                review_iterations=0\n",
        "                while not(decision == \"APPROVE\") and review_iterations < 3:\n",
        "\n",
        "                    if decision==\"REFINE\":\n",
        "                        print(f\"\\nAgent: {agent_name} needs refinement. Retrying\")\n",
        "                        result = retry_execute_agent(agent, code_to_debug, feedback)\n",
        "                    else:\n",
        "                        result = execute_agent(agent, code_to_debug)\n",
        "\n",
        "                    review = task_review(agent, result)\n",
        "                    decision = review[\"decision\"]\n",
        "                    feedback = review[\"feedback\"]\n",
        "\n",
        "                    if decision=='APPROVE':\n",
        "                        print(f\"\\nAgent: {agent_name} approved\")\n",
        "                        print(f\"\\nAgent: {agent_name} execution completed\")\n",
        "\n",
        "                    code_to_debug = result[\"fixed_code\"]\n",
        "\n",
        "\n",
        "                    review_iterations+=1\n",
        "\n",
        "\n",
        "        validation = validate_solution(code_to_debug)\n",
        "        status = validation[\"status\"]\n",
        "        summary = validation[\"summary\"]\n",
        "        re_bugs = validation[\"remaining_bugs\"]\n",
        "        if status == \"FIXED\":\n",
        "            print(f\"\\nðŸŸ¢ Bugs fixed successfully. Total number of iterations: {iteration + 1}\\n\")\n",
        "            return code_to_debug\n",
        "\n",
        "        print(\"\\nðŸŸ¡ Failed to fix the bugs. Retrying....\")\n",
        "        print(f\"\\nValidation report : \\n {summary} \\n {re_bugs}\")\n",
        "        prev_analysis_report = analysis_report\n",
        "        analysis_report = new_iteration_analyze_problem(code_to_debug, validation, analysis_report)\n",
        "\n",
        "    print(\"\\nðŸ”´ Failed to fix the bugs after max iterations.\")\n",
        "    return code_to_debug\n"
      ],
      "metadata": {
        "id": "h1SOM1MHA8Fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BUGGY CODE EXAMPLE\n"
      ],
      "metadata": {
        "id": "VaaUr4OLU5Nr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_buggy_code=\"\"\"\n",
        "def process_student_records(students, output_file):\n",
        "\n",
        "    averages = {}\n",
        "    for student in students:\n",
        "        grades = student[\"grades\"]\n",
        "        avg = sum(grades) / (len(grades) - 1)\n",
        "        averages[student[\"name\"]] = avg\n",
        "\n",
        "    top_student = max(averages, key=lambda k: averages[k])\n",
        "\n",
        "    normalized = []\n",
        "    for g in grades:\n",
        "        normalized.append(g / max(grades))\n",
        "\n",
        "    with open(output_file, \"w\") as f:\n",
        "        f.write(\"Student Averages:\\n\")\n",
        "        for name, avg in averages.items():\n",
        "            f.write(f\"{name}: {avg}\\n\")\n",
        "\n",
        "        f.write(f\"\\nTop student: {top_student} with {averages[top_student]}\\n\")\n",
        "\n",
        "    summary = \"Processed {count} students\".format(cnt=len(students))\n",
        "    f.write(summary)\n",
        "\n",
        "    f.close()\n",
        "\n",
        "    import jsonn\n",
        "    result = json.dumps({\n",
        "        \"averages\": averages,\n",
        "        \"top_student\": top_student\n",
        "    })\n",
        "\n",
        "    return result\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "f4tzqzPZfvOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXECUTION EXAMPLE"
      ],
      "metadata": {
        "id": "ic21bb2Dr-LU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_code = adaptive_debugger(example_buggy_code)\n",
        "print(\"Final Output:\\n\", fixed_code)"
      ],
      "metadata": {
        "id": "Nt5_WFbQnNh8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "collapsed": true,
        "outputId": "e8b93f19-c8d6-435f-b223-f72c138f7d70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AuthenticationError",
          "evalue": "Error code: 401 - {'id': 'oWS2jzj-3pDw3Z-9ca3dadddddc76f4', 'error': {'message': 'Invalid API key provided. You can find your API key at https://api.together.ai/settings/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-62369286.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfixed_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madaptive_debugger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplex_buggy_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Final Output:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3666310208.py\u001b[0m in \u001b[0;36madaptive_debugger\u001b[0;34m(buggy_code, max_iterations)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madaptive_debugger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuggy_code\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0manalysis_report\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_problem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuggy_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalysis_report\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0manalysis_report\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bugs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nðŸŸ¢ No errors found. Code is already fixed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2759121278.py\u001b[0m in \u001b[0;36manalyze_problem\u001b[0;34m(code)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mDo\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrite\u001b[0m \u001b[0many\u001b[0m \u001b[0mtext\u001b[0m \u001b[0mbesides\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mJSON\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \"\"\"\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_llm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mparsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_json_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"complexity\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"SIMPLE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bugs\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"plan\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"...\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-10364386.py\u001b[0m in \u001b[0;36mcall_llm\u001b[0;34m(question)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcall_llm\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mprovider\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"together\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     response = tg_client.chat.completions.create(\n\u001b[0m\u001b[1;32m      6\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"meta-llama/Llama-3.3-70B-Instruct-Turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/together/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/together/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, chat_template_kwargs, compliance, context_length_exceeded_behavior, echo, frequency_penalty, function_call, logit_bias, logprobs, max_tokens, min_p, n, presence_penalty, reasoning, reasoning_effort, repetition_penalty, response_format, safety_model, seed, stop, stream, temperature, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mNotGiven\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnot_given\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 541\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    542\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/together/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, content, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1278\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m         )\n\u001b[0;32m-> 1280\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/together/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'id': 'oWS2jzj-3pDw3Z-9ca3dadddddc76f4', 'error': {'message': 'Invalid API key provided. You can find your API key at https://api.together.ai/settings/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
          ]
        }
      ]
    }
  ]
}